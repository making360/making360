\chapter{Dailies Quickstitch}
\pagecolor{white}
\label{chap:29}
\begin{fullwidth}
% \vspace{\baselineskip}

\problem

{\large You need to quickly stitch some source footage with burnt in timecode for a review session but don't know where to start. \par}

You've just finished ingesting your source footage onto a hard disk after shooting multiple takes for many scenes. It's now time to sort and label your files into bins. As opposed to traditional post-production workflow, reviewing your dailies can't happen until your footage is stitched together. Stitching two or more videos together will first require you to organize your files properly.

\solution

{\large Organizing a project folder \par}

Each sd card corresponds to a certain camera angle. When you ingest video files from one sd card, you are uploading all the takes into one folder (ex. Camera 1, Camera 2). You will need to move the video from each camera folder into a new take folder (ex. Take 1). Here's a snapshot of how it looks before and after.

\imgA{1.5}{29/folders}

To quickly find which video files should be placed into a new take folder, open all your camera folders using the dropdown arrow. Start by highlighting the first mp4 in each camera folder, then look at the file size of each one. If it's the same or close in size for all highlighted files, the files are all from the same take. Drag them all into the new take folder. If you are unsure, you can always open the videos and view them.

Renaming source files later can be tricky so organize before stitching. Is your project is stereoscopic or monoscopic? If you shot in stereo, you will have two of each camera angle, corresponding to left/right eye. Make sure to include if the video is Left eye or Right eye in the filename.

The simple saying "for every minute spent organizing, an hour is earned" truly applies to 360 video editing. Remember you are editing the amount of take files times the number of cameras. Add a few prefixes to help you and your team down the line such as T01 for take number, HD or SD (4K/2K), C01 for camera number, LE or RE for Left Eye and Right Eye in a case of stereoscopic projects.

For example,

GOPR02355 would be T01\_HD\_C01\_GOPR02355.mp4 for a monoscopic project.

GOPR01025 would be T07\_4K\_C03\_LE\_GOPR01025.mp4 for a stereoscopic project.

{\large Quick stitching of takes \par}

To combine the individual videos into a single high resolution seamless panoramic video, you will have to "stitch" them together. Most video camera manufacturers are developing built-in functionality to ease the stitching/playback of 360 dailies. If you don't have a real-time stitching solution, you will have to stitch the videos yourself before previewing dailies. Thanks to Autopano Video Pro (AVP) from Kolor, it's just a few clicks away.

Open the "preferences" of AVP (or command + ,). Under Blend > set Blending Level to 0, Weighting to ISO Cutting, and Render settings FPS as original video.

\imgB{.75}{29/blend}{29/rendersettings}

Drag your videos into AVP. All videos must have the same length, same format (mp4 or mov) and same frames per second (fps). The accuracy of the visual sync between cameras may vary depending on the equipment used, or your set and settings. Ensure all cameras are perfectly synchronized before stitching (e.g. Apply "Use Audio to Synchronize" under Synchronization menu).

\imgA{1.53}{29/drag_videos}

Before jumping onto the stitch tab (fourth icon in the AVP header bar), select a range of frames by trimming your timeline at beginning and end using the blue range selector. Then click on the exact frame you want for the calibration. Don't leave it on the beginning frames. You don't want to confuse AVP by trying to stitch the DP's fingers or face. Save that for later during the fine stitch. 

\imgA{1.53}{29/rangeselection}

Select a stitching preset using the dropdown. The default preset will auto stitch as GoPro. If you are using different camera lens, check "Lens model" and input the focal length and lens type. For example, enter in 8mm for your focal length and fisheye for type of lens. Press "OK" and then click "Stitch" and let AVP do the rest!

\imgB{.75}{29/lensmodel}{29/lens_model_inputs}

When stitched together, your panoramic video may need to be adjusted or rotated. Hold your cursor on the preview area and drag until the horizon is aligned. Don't forget to apply your changes.

\imgB{.75}{29/panotomove}{29/panomoved}

Bravo, you have just completed your first quick stitch, now you are ready to render your work!

%\clearpage
{\large Rendering your work \par}

Rendering is the last step in any workflow. Every software you use to edit the picture or audio of a file will let you export the changes by creating a new video or audio file with the render settings you selected.

Before you start rendering, double check that all your default preferences are correct.  Consider the right fps for the playback solution of your choosing. Even if you shot at 100fps or 60fps, you will want to output at an FPS that the headsets or video player can handle. 

For example, if you want to upload your 360 video to youtube or facebook, the current allowed fps is 24, 25 or 30. For quick stitches, I generally like to set my FPS to be same "as original video" under the Render settings. Setting the default preferences will make it easier to batch render.

\imgB{.75}{29/fps25}{29/fpsoriginal}

When you are ready to hit the "render" icon, AVP will bring a pop up some presets to choose from and show the maximum output size. The maximum output size is the resolution achieved from your 360 camera rig. Depending on the rig you chose, the final resolution after stitching can range from 4k to 8k. Presets are very valuable during stitching and you will want to get familiar with all the choices. When you want to render small files quickly to test and find seams to fix, you can output at a lower resolution such as 2k. Remember to change the settings back for your final render. You can always check at the bottom of the pop up window what resolution and frame rate the video will render as. For the GearVR, render your videos at 3840x1920 or 4096x2048 when shooting 4k (1920x960 is SD).

When rendering your fine stitch, it is highly recommended to render output type as frames, a sequence of uncompressed tiff images at 16 bit color depth. You will want to render frames to keep the highest resolution of your panorama and the maximum size allowed. There are limitations when you render videos. The bit depth will be between 8 to 10 bit, including the AVI uncompressed option, and there are size limits (for example: h264 mp4 maximum height at 2304px). Rendering tiff sequences will allow you to keep the maximum output resolution and quality. Your footage will be running through many processes down the pipeline. From stitching to vfx to editing to color grading, pixels will get distorted down the line. You will want to work and keep the files with at highest resolution and quality, starting with AVP. Output TIFF Frames at 16 bit, and No compression in AVP.

\imgA{1}{29/exportingtiffs}

\tip Removing alpha channel when exporting tiffs will reduce the size of each tiff. Recommended for large sequences.

Every time you render, you are creating a new file. Stay organized so you know what version each render is. Add a prefix to every file. Use QS for Quickstitch, a version number \_v001 for your tests, and FS for Fine Stitch. When rendering frames, select an output folder with the suffix  \_tiff in the name.

\clearpage
{\large Encoding a burnt-in timecode \par}

\imgA{1.53}{29/terminal}

You can use After Effects, Premiere or any video editing software to encode a timecode or you can do it...the "hard" way aka not really, just geeky but in reality faster way! Hello FFMpeg! Don't let the terminal or command lines scare you!

For Mac users, the "drawtext" filter of FFmpeg is only working with this FFmpeg library. Unzip the 7zip file using Keka, then place the ~30mb "ffmpeg" file in the directory where all the libraries live, usually /usr/local/bin/ffmpeg.

Show/Hide Hidden Folders and Files on Mac:

\code{defaults write com.apple.finder AppleShowAllFiles YES} \par
\code{defaults write com.apple.finder AppleShowAllFiles NO}

Open the Terminal app on Mac. Use the basic commands to access the directory where your stitched video is located.

\tip If your Finder is opened with your video visible, drag the folder icon into the Terminal window AFTER typing "cd" (e.g. change directory).

Type the exact FFmpeg script for the action you want to perform on the video: embedding a timecode in center of video, at the same framerate as video.

\code{ffmpeg -i video.mp4}

Run FFmpeg by simply the typing "ffmpeg" in the terminal. FFmpeg takes a video in and creates a new video out. Let's tell ffmpeg where and which video you want as input. Just type "-i" and the path/name of your file.

\code{ffmpeg -i video.mp4 video\_tc.mp4}

Type the name for the output file. This FFmpeg script doesn't really perform any action besides renaming the output file. If you want to change the extension of the output filename to .mov, FFmpeg will operate a conversion of your video from MP4 to MOV.

To add any kind of text or timecode on your video, use the filter "drawtext" after calling it via -vf command before the output, such as:

\code{ffmpeg -i video.mp4 -vf "drawtext=" video\_tc.mp4}

Select a monospaced font file from your machine:

\code{fontfile='/Library/Fonts/Arial.ttf':}

Then add the format for the timecode including the framerate (matching same fps as video), font size, color, and position on the video:

\code{timecode='00\\:00\\:00;00':r=29.97: fontsize=32: fontcolor=white: x=(w)/2:y=(h)/2}

Note the colons are required between each argument. Put all of this together into one command line:

\code{ffmpeg -i video.mp4 -vf "drawtext=fontfile='/Library/Fonts/Arial.ttf':timecode='00\\:00\\:00;00':r=29.97:fontsize=32:fontcolor=white:x=(w)/2:y=(h)/2" video\_tc.mp4}


Press RETURN after pasting this line into your Terminal and  FFmpeg will render the video again with the timecode on it. Good Job!


\clearpage

\end{fullwidth}